# Indice

- Introducción
  - Sistemas de condución autónomos
  - Sistemas de percepción
    - Principales sensores para la percepción en vehículos autónomos
      - LiDAR
      - Cámara
      - Radar
    - Sistemas de detección
      - 2D
      - 3D
    - Tracking
    - Fusión sensorial
- Propuesta de trabajo
- Sistemas clásicos de percepción con LiDAR
  - Voxelización
  - Ransac-3D
  - KD-tree
  - Filtrados
    - Basado en candidad de puntos
    - Basado en la distancia entre puntos
- Sistemas de percepción con LiDAR basados en Deep Learning
  - Datasets
    - Kitti
      - Formato de los datos
        - Análisis del ground truth
      - Métricas
    - nuScenes
      - Formato de los datos
      - devkit nuScenes
      - Métricas
    - Waymo
      - Formato de los datos
      - Métricas
    - Comparativa
  - Modelos en el estado del arte
    - PointPillars
    - SECOND
    - PointRCNN
    - PV-RCNN
    - CBGS
  - OpenPCDet
- Desarrollo realizado
  - Estado del proyecto T4AC
    - ROS
    - Docker
  - Implementación en CARLA
    - CARLA
    - Funcionamiento del LiDAR en CARLA
    - Tratado de datos aplicado
  - Implementación sobre el vehículo T4AC
  - Fusión sensorial
- Resultados obtenidos
  - Análisis cuantitativo en Kitti
  - Análisis cuantitativo en nuScenes
  - Análisis cualitativo del modelo clásico en CARLA
  - Análisis cualitativo de CBGS en CARLA
    - Comparación con Poinpillars
  - Análisis cualitativo de CBGS sobre el vehículo T4AC
    - Comparación con Poinpillars
- Conclusiones
  - Comparativas adicionales
    - Ajuste de modelos basados en Kitti a nuScenes
    - Número de PCL de entrada
    - Tamaño del voxel
  - Futuros trabajos