%%%%%%%%%%%%%%%%%
%% TFGs y TFMs %%
%%%%%%%%%%%%%%%%%

@mastersthesis{tfg_miguel,
  author = {Miguel Antunes},
  title = {Sistema de visión estereo aplicado a la detección y seguimiento de objetos en conducción autonoma},
  school = {UAH Politécnica},
  year = {2021},
  type = {Trabajo de Fin de Grado},
}

@mastersthesis{tfm_del_egido,
  author = {Javier del Egido Sierra},
  title = {Detección del entorno 360º de un vehículo autónomo mediante LIDAR aplicando técnicas Deep Learning},
  school = {UAH Politécnica},
  year = {2020},
  type = {Trabajo de Fin de Master},
}

@mastersthesis{tfm_felipe,
  author = {Juan Felipe Arango Vargas},
  title = {Diseño de un sistema Drive-By-Wire para un vehiculo autónomo},
  school = {UAH Politécnica},
  year = {2020},
  type = {Trabajo de Fin de Master},
}

%%%%%%%%%%%%%%%
%% Web pages %%
%%%%%%%%%%%%%%%

@techreport{automated_vehicles_for_safety,
  title = {Automated Vehicles for Safety},
  url = {https://www.nhtsa.gov/technology-innovation/automated-vehicles-safety},
  orgatization = {National Highway Traffic Safety Administration},
  year = {2018}
}

@techreport{how_self_driving_vehicles_work,
  title = {How Self-driving Cars Work: Sensor Systems},
  url = {https://www.udacity.com/blog/2021/03/how-self-driving-cars-work-sensor-systems.html},
  orgatization = {Udacity},
  year = {2021}
}

@misc{velodyne_hdl_64,
  title = {HDL-64E, High Definition Real-Time 3D Lidar},
  url = {https://velodynelidar.com/products/hdl-64e/},
  organization = {Velodyne Lidar},
}

@misc{waymo_web_page,
  title = {Waymo Open Dataset},
  url = {https://waymo.com/open},
  organization = {Waymo},
}

@misc{sparseconvnet,
  title = {SparseConvNet},
  url = {https://github.com/facebookresearch/SparseConvNet},
  organization = {Facebook},
  type = {GitHub repository},
}

@misc{openpcdet,
  title={OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Clouds},
  author={OpenPCDet Development Team},
  howpublished = {\url{https://github.com/open-mmlab/OpenPCDet}},
  year={2020}
}

@misc{ros_wiki,
  title={ROS introduction},
  author={ROS Community},
  url = {http://wiki.ros.org/ROS/Introduction},
  year={2020}
}

@misc{docker_wikipedia,
title={Docker (software)},
author={Wikipedia Community},
url = {https://es.wikipedia.org/wiki/Docker_(software)},
year={2021}
}

@misc{docker_docs,
  title={Docker overview},
  author={Docker Team},
  url = {https://docs.docker.com/get-started/overview/}
}

@misc{opendrive,
  title={ASAM OpenDRIVE®},
  author={Association for Standarization of Automation and Measuring Systems},
  url = {https://www.asam.net/standards/detail/opendrive/}
}

@misc{carla_intro,
  title={CARLA introduction},
  author={CARLA team},
  url = {https://carla.readthedocs.io/en/0.9.12/start_introduction/}
}

%%%%%%%%%%%%%
%% Article %%
%%%%%%%%%%%%%

@ARTICLE{computing_system_for_autonomous_driving,
  author={Liu, Liangkai and Lu, Sidi and Zhong, Ren and Wu, Baofu and Yao, Yongtao and Zhang, Qingyang and Shi, Weisong}, 
  journal={IEEE Internet of Things Journal},
  title={Computing Systems for Autonomous Driving: State of the Art and Challenges},
  year={2021},
  volume={8},
  number={8},
  pages={6469-6486},
  doi={10.1109/JIOT.2020.3043716}
}

@INPROCEEDINGS{fusion_lidar_radar_and_camera,
  author={Kim, Taek-Lim and Lee, Jae-Seol and Park, Tae-Hyoung}, 
  booktitle={2019 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)},  
  title={Fusing Lidar, Radar, and Camera Using Extended Kalman Filter for Estimating the Forward Position of Vehicles},  
  year={2019}, 
  pages={374-379}, 
  doi={10.1109/CIS-RAM47153.2019.9095859}
}

@INPROCEEDINGS{doppler,
  author={Zhang, Yewen and Ran, Jia and Chen, Xiaodong and Fang, Kai and Chen, Hong},
  booktitle={2015 IEEE 4th Asia-Pacific Conference on Antennas and Propagation (APCAP)},
  title={Observation of the inverse, zero and normal Doppler effect in configurable transmission lines},
  year={2015},
  pages={229-230},
  doi={10.1109/APCAP.2015.7374348}
}

@ARTICLE{lidar_adverse_weather_conditions,
  author={Wallace, Andrew M. and Halimi, Abderrahim and Buller, Gerald S.},
  journal={IEEE Transactions on Vehicular Technology},
  title={Full Waveform LiDAR for Adverse Weather Conditions},
  year={2020},
  volume={69},
  number={7},
  pages={7064-7077},
  doi={10.1109/TVT.2020.2989148}
}

@INPROCEEDINGS{yolo,
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={You Only Look Once: Unified, Real-Time Object Detection},
  year={2016},
  pages={779-788},
  doi={10.1109/CVPR.2016.91}
}

@INPROCEEDINGS{pointpillars,
  author={Lang, Alex H. and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={PointPillars: Fast Encoders for Object Detection From Point Clouds},
  year={2019},
  pages={12689-12697},
  doi={10.1109/CVPR.2019.01298}
}

@INPROCEEDINGS{tracking_based_on_rnn,
  author={Lotfi, F. and Ajallooeian, V. and Taghirad, H. D.},
  booktitle={2018 6th RSI International Conference on Robotics and Mechatronics (IcRoM)},
  title={Robust Object Tracking Based on Recurrent Neural Networks},
  year={2018},
  pages={507-511},
  doi={10.1109/ICRoM.2018.8657608}
}

@ARTICLE{pointtracknet,
  author={Wang, Sukai and Sun, Yuxiang and Liu, Chengju and Liu, Ming},
  journal={IEEE Robotics and Automation Letters},
  title={PointTrackNet: An End-to-End Network For 3-D Object Detection and Tracking From Point Clouds},
  year={2020},
  volume={5},
  number={2},
  pages={3206-3212},
  doi={10.1109/LRA.2020.2974392}
}

@article{ransac,
  author = {Fischler, Martin A. and Bolles, Robert C.},
  title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  year = {1981},
  issue_date = {June 1981},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {24},
  number = {6},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/358669.358692},
  doi = {10.1145/358669.358692},
  abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental
  data is introduced. RANSAC is capable of interpreting/smoothing data containing a
  significant percentage of gross errors, and is thus ideally suited for applications
  in automated image analysis where interpretation is based on the data provided by
  error-prone feature detectors. A major portion of this paper describes the application
  of RANSAC to the Location Determination Problem (LDP): Given an image depicting a
  set of landmarks with known locations, determine that point in space from which the
  image was obtained. In response to a RANSAC requirement, new results are derived on
  the minimum number of landmarks needed to obtain a solution, and algorithms are presented
  for computing these minimum-landmark solutions in closed form. These results provide
  the basis for an automatic system that can solve the LDP under difficult viewing},
  journal = {Commun. ACM},
  month = jun,
  pages = {381-395},
  numpages = {15},
  keywords = {scene analysis, model fitting, location determination, camera calibration, image matching, automated cartography}
}

@article{kd_tree,
  author = {Bentley, Jon Louis},
  title = {Multidimensional Binary Search Trees Used for Associative Searching},
  year = {1975},
  issue_date = {Sept. 1975},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {18},
  number = {9},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/361002.361007},
  doi = {10.1145/361002.361007},
  abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k
  is the dimensionality of the search space) as a data structure for storage of information
  to be retrieved by associative searches. The k-d tree is defined and examples are
  given. It is shown to be quite efficient in its storage requirements. A significant
  advantage of this structure is that a single data structure can handle many types
  of queries very efficiently. Various utility algorithms are developed; their proven
  average running times in an n record file are: insertion, O(log n); deletion of the
  root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees
  logarithmic performance of searches), O(n log n). Search algorithms are given for
  partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)]
  and for nearest neighbor queries [empirically observed average running time of O(log
  n).] These performances far surpass the best currently known algorithms for these
  tasks. An algorithm is presented to handle any general intersection query. The main
  focus of this paper is theoretical. It is felt, however, that k-d trees could be quite
  useful in many applications, and examples of potential uses are given.},
  journal = {Commun. ACM},
  month = sep,
  pages = {509-517},
  numpages = {9},
  keywords = {attribute, intersection queries, nearest neighbor queries, partial match queries, binary tree insertion, information retrieval system, key, binary search trees, associative retrieval}
}

@INPROCEEDINGS{knn_kd_tree,
  author={Hou, Wenfeng and Li, Daiwei and Xu, Chao and Zhang, Haiqing and Li, Tianrui},
  booktitle={2018 IEEE International Conference of Safety Produce Informatization (IICSPI)},
  title={An Advanced k Nearest Neighbor Classification Algorithm Based on KD-tree},
  year={2018},
  pages={902-905},
  doi={10.1109/IICSPI.2018.8690508}
}

@INPROCEEDINGS{kd_tree_presorted,
  author={Cao, Yu and Zhang, Xiaojiang and Duan, Boheng and Zhao, Wenjing and Wang, Huizan},
  booktitle={2020 IEEE 11th International Conference on Software Engineering and Service Science (ICSESS)},
  title={An Improved Method to Build the KD Tree Based on Presorted Results},
  year={2020},
  pages={71-75},
  doi={10.1109/ICSESS49938.2020.9237636}
}

@INPROCEEDINGS{kd_tree_gpu,
  author={Hu, Linjia and Nooshabadi, Saeid and Ahmadi, Majid},
  booktitle={2015 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title={Massively parallel KD-tree construction and nearest neighbor search algorithms},
  year={2015},
  pages={2752-2755},
  doi={10.1109/ISCAS.2015.7169256}
}

@misc{a2d2_dataset,
  title={A2D2: Audi Autonomous Driving Dataset}, 
  author={Jakob Geyer and Yohannes Kassahun and Mentar Mahmudi and Xavier Ricou and Rupesh Durgesh and Andrew S. Chung and Lorenz Hauswald and Viet Hoang Pham and Maximilian Mühlegg and Sebastian Dorn and Tiffany Fernandez and Martin Jänicke and Sudesh Mirashi and Chiragkumar Savani and Martin Sturm and Oleksandr Vorobiov and Martin Oelker and Sebastian Garreis and Peter Schuberth},
  year={2020},
  eprint={2004.06320},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@InProceedings{argoverse_dataset,
  author = {Chang, Ming-Fang and Lambert, John and Sangkloy, Patsorn and Singh, Jagjeet and Bak, Slawomir and Hartnett, Andrew and Wang, De and Carr, Peter and Lucey, Simon and Ramanan, Deva and Hays, James},
  title = {Argoverse: 3D Tracking and Forecasting With Rich Maps},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2019}
}

@InProceedings{cityscapes_dataset,
  author = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  title = {The Cityscapes Dataset for Semantic Urban Scene Understanding},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2016}
}

@INPROCEEDINGS{kitti_dataset,
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Are we ready for autonomous driving? The KITTI vision benchmark suite}, 
  year={2012},
  volume={},
  number={},
  pages={3354-3361},
  doi={10.1109/CVPR.2012.6248074}
}

@misc{level_5_dataset,
  title={One Thousand and One Hours: Self-driving Motion Prediction Dataset}, 
  author={John Houston and Guido Zuidhof and Luca Bergamini and Yawei Ye and Long Chen and Ashesh Jain and Sammy Omari and Vladimir Iglovikov and Peter Ondruska},
  year={2020},
  eprint={2006.14480},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@InProceedings{nuscenes_dataset,
  author = {Caesar, Holger and Bankiti, Varun and Lang, Alex H. and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  title = {nuScenes: A Multimodal Dataset for Autonomous Driving},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2020}
}

@InProceedings{waymo_dataset,
  author = {Sun, Pei and Kretzschmar, Henrik and Dotiwalla, Xerxes and Chouard, Aurelien and Patnaik, Vijaysai and Tsui, Paul and Guo, James and Zhou, Yin and Chai, Yuning and Caine, Benjamin and Vasudevan, Vijay and Han, Wei and Ngiam, Jiquan and Zhao, Hang and Timofeev, Aleksei and Ettinger, Scott and Krivokon, Maxim and Gao, Amy and Joshi, Aditya and Zhang, Yu and Shlens, Jonathon and Chen, Zhifeng and Anguelov, Dragomir},
  title = {Scalability in Perception for Autonomous Driving: Waymo Open Dataset},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2020}
}

@INPROCEEDINGS{kitti_360_dataset,
author = {Jun Xie and Martin Kiefel and Ming-Ting Sun and Andreas Geiger},
title = {Semantic Instance Annotation of Street Scenes by 3D to 2D Label Transfer},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2016}
}

@Article{second,
  AUTHOR = {Yan, Yan and Mao, Yuxing and Li, Bo},
  TITLE = {SECOND: Sparsely Embedded Convolutional Detection},
  JOURNAL = {Sensors},
  VOLUME = {18},
  YEAR = {2018},
  NUMBER = {10},
  ARTICLE-NUMBER = {3337},
  URL = {https://www.mdpi.com/1424-8220/18/10/3337},
  ISSN = {1424-8220},
  ABSTRACT = {LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data. However, problems remain, including a slow inference speed and low orientation estimation performance. We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.},
  DOI = {10.3390/s18103337}
}

@INPROCEEDINGS{pointrcnn,
  author={Shi, Shaoshuai and Wang, Xiaogang and Li, Hongsheng},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={PointRCNN: 3D Object Proposal Generation and Detection From Point Cloud}, 
  year={2019},
  volume={},
  number={},
  pages={770-779},
  doi={10.1109/CVPR.2019.00086}
}

@INPROCEEDINGS{pv_rcnn,
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection}, 
  year={2020},
  volume={},
  number={},
  pages={10526-10535},
  doi={10.1109/CVPR42600.2020.01054}
}

@article{cbgs,
  author    = {Benjin Zhu and Zhengkai Jiang and Xiangxin Zhou and Zeming Li and Gang Yu},
  title     = {Class-balanced Grouping and Sampling for Point Cloud 3D Object Detection},
  journal   = {CoRR},
  volume    = {abs/1908.09492},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.09492},
  archivePrefix = {arXiv},
  eprint    = {1908.09492},
  timestamp = {Thu, 29 Aug 2019 16:32:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-09492.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{voxelnet,
  author={Zhou, Yin and Tuzel, Oncel},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title={VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection},
  year={2018},
  pages={4490-4499},
  doi={10.1109/CVPR.2018.00472}
}

@InProceedings{fast_rcnn,
  author = {Girshick, Ross},
  title = {Fast R-CNN},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month = {December},
  year = {2015}
}

@misc{pointnet++,
  title={PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space}, 
  author={Charles R. Qi and Li Yi and Hao Su and Leonidas J. Guibas},
  year={2017},
  eprint={1706.02413},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@misc{rangercnn,
  title={RangeRCNN: Towards Fast and Accurate 3D Object Detection with Range Image Representation}, 
  author={Zhidong Liang and Ming Zhang and Zehan Zhang and Xian Zhao and Shiliang Pu},
  year={2021},
  eprint={2009.00206},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@INPROCEEDINGS{pointnet,
  author={Charles, R. Qi and Su, Hao and Kaichun, Mo and Guibas, Leonidas J.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
  year={2017},
  pages={77-85},
  doi={10.1109/CVPR.2017.16}
}

@incollection{pytorch,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor = {H. Wallach and H. Larochelle and A. Beygelzimer and E. Fox and R. Garnett},
  pages = {8024--8035},
  year = {2019},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@misc{part-a2,
  title={From Points to Parts: 3D Object Detection from Point Cloud with Part-aware and Part-aggregation Network}, 
  author={Shaoshuai Shi and Zhe Wang and Jianping Shi and Xiaogang Wang and Hongsheng Li},
  year={2020},
  eprint={1907.03670},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@misc{voxel_rcnn,
  title={Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection}, 
  author={Jiajun Deng and Shaoshuai Shi and Peiwei Li and Wengang Zhou and Yanyong Zhang and Houqiang Li},
  year={2021},
  eprint={2012.15712},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@InProceedings{caddn,
  author = {Reading, Cody and Harakeh, Ali and Chae, Julia and Waslander, Steven L.},
  title = {Categorical Depth Distribution Network for Monocular 3D Object Detection},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2021},
  pages = {8555-8564}
}

@software{ros,
  author = {{Stanford Artificial Intelligence Laboratory et al.}},
  title = {Robotic Operating System},
  url = {https://www.ros.org},
  version = {ROS Melodic Morenia},
  date = {2018-05-23},
}

@article{docker,
  title={Docker: lightweight linux containers for consistent development and deployment},
  author={Merkel, Dirk},
  journal={Linux journal},
  volume={2014},
  number={239},
  pages={2},
  year={2014}
}

@inproceedings{carla,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

@software{unrealengine,
  author = {{Epic Games}},
  title = {Unreal Engine},
  url = {https://www.unrealengine.com},
  version = {4.22.1},
  date = {2019-04-25},
}

@INPROCEEDINGS{smartmot,
  author={Gómez-Huélamo, Carlos and Del Egido, Javier and Bergasa, Luis M. and Barea, Rafael and Ocaña, Manuel and Arango, Felipe and Gutiérrez-Moreno, Rodrigo},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  title={Real-Time Bird?s Eye View Multi-Object Tracking system based on Fast Encoders for Object Detection},
  year={2020},
  pages={1-6},
  doi={10.1109/ITSC45102.2020.9294737}
}

@InProceedings{red_volumetrica,
  author = {Mousavian, Arsalan and Anguelov, Dragomir and Flynn, John and Kosecka, Jana},
  title = {3D Bounding Box Estimation Using Deep Learning and Geometry},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {July},
  year = {2017}
}