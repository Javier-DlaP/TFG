\chapter{Resultados obtenidos}
\label{cha:resultados_obtenidos}

\begin{FraseCelebre}
  \begin{Frase}
    Ninguna investigación humana puede ser llamada ciencia real si no puede demostrarse matemáticamente.
  \end{Frase}
  \begin{Fuente}
    Leonardo da Vinci
  \end{Fuente}
\end{FraseCelebre}

\noindent
Este capítulo muestra los resultados de los diferentes modelos y algoritmos presentados para la detección 3D con \acs{lidar} sobre: datasets, el simulador CARLA y el vehículo T4AC.\par
Las métricas de tiempo de todos los modelos han sido realizadas sobre un ordenador con un procesador AMD Ryzen 3700X y una tarjeta gráfica NVIDIA RTX 2060 Super.\par
Para la visualización de los resultados sobre CARLA y sobre el vehículo T4AC en el campus de la Universidad de Alcalá, se presenta un vídeo en \url{https://youtu.be/9vLnA27dmns} con en el desarrollo realizado sobre la arquitectura del proyecto Techs4AgeCar.

\section{Análisis sobre datasets}
\label{sec:analisis_sobre_datasets}

Los modelos explicados en el capítulo \ref{sec:estado_del_arte_en_deteccion_utilizando_lidar} se evalúan en este apartado, cada uno en el dataset donde han sido entrenados: SECOND, PointPillars, PointRCNN y PV-RCNN en KITTI, y CBGS en nuScenes, para mostrar de esta manera la precisión de dichos modelos.\par
Para la evaluación de ambos modelos se han descargado las versiones completas de KITTI y nuScenes junto con los modelos y sus pesos, analizando en cada uno las métricas utilizadas en su respectivo dataset.

\subsection{Análisis cuantitativo en Kitti}
\label{sec:analisis_cuantitativo_en_kitti}

La evaluación sobre el dataset KITTI consta de los modelos: SECOND, PointPillars, PointRCNNy PV-RCNN. Dichos modelos se evalúan en los benchmark de detección, orientación, detección 3D y \acs{bev}, tanto como análisis general del modelo como análisis por clase en cada uno de los modelos.\par
KITTI requiere de un \acs{iou} mínimo del 70\% para dar por correcta una detección con la clase coche, mientras que para los ciclistas y peatones solo se requiere de un \acs{iou} del 50\%. Es necesario tener en cuenta que en este dataset se utilizan 3 dificultades diferentes, donde en la evaluación fácil se utilizan los objetos con un máximo de 15\% de oclusión, en la evaluación moderada un máximo del 30\% y en la evaluación difícil un máximo del 50\%.\par
El cálculo del \acs{ap} para los benchmark de detección 2D, vista de pájaro y detección 3D, se realiza a partir del área bajo la curva de precision-recall, construida con 40 límites para su mayor precisión en la evaluación.

\begin{center}
$AOS = \dfrac{1}{40} \displaystyle\sum_{r \in {0,0 \centerdot 25, \dots ,1}} \max_{\bar{r} : \bar{r} \geq r} s(\bar{r})$\\[10pt]
recall: $r = \dfrac{TP}{TP+FN}$\\[10pt]
$s(r) = \dfrac{1}{|\mathcal{D}(r)|} \displaystyle\sum_{i \in \mathcal{D}(r)} \dfrac{1+\cos{\Delta_{\theta}^{(i)}}}{2} \delta _{i}$
\end{center}

Mientras que para la estimación de la orientación se utiliza la métrica \ac{aos} con un valor que oscila entre 0 y 1, siendo 1 la orientación perfecta.

\begin{center}
\begin{longtable}{|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\hline
\endfirsthead
\multicolumn{5}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\endhead
\hline \multicolumn{5}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
\multirow{4}{*}{Coche}
& Detección & 95.61 \% & 75.39 \% & 77.47 \%\\
\cline{2-5}
& Vista de pájaro & 84.62 \% & 65.57 \% & 63.14 \%\\
\cline{2-5}
& Detección 3D & 74.15 \% & 54.27 \% & 50.98 \%\\
\cline{2-5}
& Orientación & 95.58 \% & 75.31 \% & 77.31 \%\\
\hline
\multirow{4}{*}{Peatón}
& Detección & 68.12 \% & 63.66 \% & 60.34 \%\\
\cline{2-5}
& Vista de pájaro & 10.14 \% & 9.62 \% & 8.55 \%\\
\cline{2-5}
& Detección 3D & 5.57 \% & 5.09 \% & 4.49 \%\\
\cline{2-5}
& Orientación & 63.55 \% & 58.45 \% & 55.06 \%\\
\hline
\multirow{4}{*}{Ciclista}
& Detección & 91.14 \% & 64.77 \% & 61.99 \%\\
\cline{2-5}
& Vista de pájaro & 67.30 \% & 43.51 \% & 41.26 \%\\
\cline{2-5}
& Detección 3D & 54.98 \% & 34.98 \% & 33.29 \%\\
\cline{2-5}
& Orientación & 90.99 \% & 64.59 \% & 61.77 \%\\
\hline
\caption{Análisis por clase de SECOND en KITTI.}
\label{tab:analisis_por_clase_de_sencond_en_kitti}
\end{longtable}
\end{center}

\vspace{-1cm}

\begin{center}
\begin{longtable}{|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\hline
\endfirsthead
\multicolumn{5}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\endhead
\hline \multicolumn{5}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
\multirow{4}{*}{Coche}
& Detección & 95.54 \% & 74.76 \% & 75.24 \%\\
\cline{2-5}
& Vista de pájaro & 87.12 \% & 67.08 \% & 64.68 \%\\
\cline{2-5}
& Detección 3D & 78.07 \% & 57.58 \% & 52.85 \%\\
\cline{2-5}
& Orientación & 95.52 \% & 74.67 \% & 75.06 \%\\
\hline
\multirow{4}{*}{Peatón}
& Detección & 66.39 \% & 61.58 \% & 58.21 \%\\
\cline{2-5}
& Vista de pájaro & 24.56 \% & 23.77 \% & 21.33 \%\\
\cline{2-5}
& Detección 3D & 15.86 \% & 15.03 \% & 13.47 \%\\
\cline{2-5}
& Orientación & 45.76 \% & 42.35 \% & 39.46 \%\\
\hline
\multirow{4}{*}{Ciclista}
& Detección & 88.41 \% & 60.70 \% & 57.32 \%\\
\cline{2-5}
& Vista de pájaro & 76.76 \% & 48.92 \% & 46.30 \%\\
\cline{2-5}
& Detección 3D & 68.06 \% & 43.23 \% & 40.46 \%\\
\cline{2-5}
& Orientación & 87.81 \% & 59.64 \% & 56.26 \%\\
\hline
\caption{Análisis por clase de PointPillars en KITTI.}
\label{tab:analisis_por_clase_de_pointpillars_en_kitti}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\hline
\endfirsthead
\multicolumn{5}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\endhead
\hline \multicolumn{5}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
\multirow{4}{*}{Coche}
& Detección & 96.51 \% & 78.63 \% & 78.68 \%\\
\cline{2-5}
& Vista de pájaro & 93.26 \% & 75.47 \% & 75.46 \%\\
\cline{2-5}
& Detección 3D & 91.71 \% & 69.82 \% & 69.54 \%\\
\cline{2-5}
& Orientación & 96.49 \% & 78.59 \% & 78.60 \%\\
\hline
\multirow{4}{*}{Peatón}
& Detección & 74.73 \% & 66.59 \% & 61.16 \%\\
\cline{2-5}
& Vista de pájaro & 64.49 \% & 58.17 \% & 51.48 \%\\
\cline{2-5}
& Detección 3D & 60.53 \% & 54.28 \% & 47.50 \%\\
\cline{2-5}
& Orientación & 71.76 \% & 63.17 \% & 57.71 \%\\
\hline
\multirow{4}{*}{Ciclista}
& Detección & 96.91 \% & 66.66 \% & 63.89 \%\\
\cline{2-5}
& Vista de pájaro & 92.35 \% & 62.41 \% & 59.39 \%\\
\cline{2-5}
& Detección 3D & 88.98 \% & 61.01 \% & 56.88 \%\\
\cline{2-5}
& Orientación & 96.82 \% & 66.23 \% & 63.45 \%\\
\hline
\caption{Análisis por clase de PointRCNN en KITTI.}
\label{tab:analisis_por_clase_de_pointrcnn_en_kitti}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\hline
\endfirsthead
\multicolumn{5}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\multicolumn{2}{|c|}{\textbf{Benchmark}} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil}\\
\hline
\endhead
\hline \multicolumn{5}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
\multirow{4}{*}{Coche}
& Detección & 97.21 \% & 77.30 \% & 77.69 \%\\
\cline{2-5}
& Vista de pájaro & 92.48 \% & 73.67 \% & 74.08 \%\\
\cline{2-5}
& Detección 3D & 89.46 \% & 69.74 \% & 70.02 \%\\
\cline{2-5}
& Orientación & 97.17 \% & 77.19 \% & 77.49 \%\\
\hline
\multirow{4}{*}{Peatón}
& Detección & 46.47 \% & 46.87 \% & 47.41 \%\\
\cline{2-5}
& Vista de pájaro & 32.67 \% & 32.47 \% & 31.59 \%\\
\cline{2-5}
& Detección 3D & 29.42 \% & 29.07 \% & 27.87 \%\\
\cline{2-5}
& Orientación & 41.55 \% & 41.21 \% & 41.47 \%\\
\hline
\multirow{4}{*}{Ciclista}
& Detección & 89.72 \% & 64.60 \% & 62.31 \%\\
\cline{2-5}
& Vista de pájaro & 85.62 \% & 56.86 \% & 53.10 \%\\
\cline{2-5}
& Detección 3D & 80.93 \% & 53.25 \% & 49.52 \%\\
\cline{2-5}
& Orientación & 88.62 \% & 63.66 \% & 61.40 \%\\
\hline
\caption{Análisis por clase de PV-RCNN en KITTI.}
\label{tab:analisis_por_clase_de_pv_rcnn_en_kitti}
\end{longtable}
\end{center}

Las clases de peatón y ciclista, como se puede ver principalmente en los modelos SECOND y PointPillars, al ser valuados sobre KITTI obtienen una precisión muy baja, esto es debido a que dichas clases son detectadas con muy pocos puntos de la nube de puntos correspondiente, por lo que no es muy preciso en dichas clases. Para evaluar de forma más significativa y comparar los diferentes modelos se evalúan las tareas de detección 3D y \acs{bev} con un \acs{iou} de 0.7 y 0.5 en coches, y para el caso de peatones y ciclistas de  de 0.5 y 0.25.

\begin{center}
\begin{longtable}{|c|c|c|c|c|c|c|}
\hline
\textbf{Modelo} & \textbf{Benchmark} & \textbf{Min. IoU} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil} & \textbf{Velocidad}\\
\hline
\endfirsthead
\multicolumn{7}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Modelo} & \textbf{Benchmark} & \textbf{Min. IoU} & \textbf{Fácil} & \textbf{Moderado} & \textbf{Difícil} & \textbf{Velocidad}\\
\hline
\endhead
\hline \multicolumn{7}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
SECOND & Detección & 0.7 - 0.5 & 84.96 \% & 67.94 \% & 66.6 \% & 18.59 Hz\\
\hline
\multirow{5}{*}{SECOND}
& \multirow{2}{*}{Vista de pájaro} & 0.7 - 0.5 & 54.02 \% & 39.57 \% & 37.65 \% &
\multirow{5}{*}{18.59 Hz}\\
\cline{3-6}
& & 0.5 - 0.25 & 86.40 \% & 70.29 \% & 68.72 \% &\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Detección 3D} & 0.7 - 0.5 & 44.90 \% & 31.45 \% & 29.59 \% &\\
\cline{3-6}
& & 0.5 - 0.25 & 86.11 \% & 69.75 \% & 67.81 \% &\\
\cline{2-3}
\cline{4-6}
& Orientación & 0.7 - 0.5 & 83.37 \% & 66.12 \% & 64.71 \% &\\
\hline
\multirow{6}{*}{PointPillars}
& Detección & 0.7 - 0.5 & 83.45 \% & 65.68 \% & 63.59 \% &
\multirow{6}{*}{\textbf{37.29 Hz}}\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Vista de pájaro} & 0.7 - 0.5 & 62.81 \% & 46.59 \% & 44.10 \% &\\
\cline{3-6}
& & 0.5 - 0.25 & 85.83 \% & 67.86 \% & 66.45 \% &\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Detección 3D} & 0.7 - 0.5 & 54.00 \% & 38.61 \% & 35.59 \% &\\
\cline{3-6}
& & 0.5 - 0.25 & 85.85 \% & 67.66 \% & 65.47 \% &\\
\cline{2-3}
\cline{4-6}
& Orientación & 0.7 - 0.5 & 76.36 \% & 58.89 \% & 56.92 \% &\\
\hline
\multirow{6}{*}{PointRCNN}
& Detección & 0.7 - 0.5 & \textbf{89.38} \% & \textbf{70.63} \% & \textbf{67.91} \% &
\multirow{6}{*}{8.62 Hz}\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Vista de pájaro} & 0.7 - 0.5 & 83.37 \% & \textbf{65.02} \% & \textbf{62.11} \% &\\
\cline{3-6}
& & 0.5 - 0.25 & \textbf{91.32} \% & \textbf{72.79} \% & \textbf{70.10} \% &\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Detección 3D} & 0.7 - 0.5 & \textbf{80.41} \% & \textbf{61.70} \% & \textbf{57.97} \% &\\
\cline{3-6}
& & 0.5 - 0.25 & \textbf{91.27} \% & \textbf{72.73} \% & \textbf{70.01} \% &\\
\cline{2-3}
\cline{4-6}
& Orientación & 0.7 - 0.5 & \textbf{88.36} \% & \textbf{69.33} \% & \textbf{66.59} \% &\\
\hline
\multirow{6}{*}{PV-RCNN}
& Detección & 0.7 - 0.5 & 77.8 \% & 62.92 \% & 62.47 \% &
\multirow{6}{*}{5.39 Hz}\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Vista de pájaro} & 0.7 - 0.5 & \textbf{86.10} \% & 54.33 \% & 52.92 \% &\\
\cline{3-6}
& & 0.5 - 0.25 & 78.23 \% & 63.24 \% & 63.61 \% &\\
\cline{2-3}
\cline{4-6}
& \multirow{2}{*}{Detección 3D} & 0.7 - 0.5 & 66.60 \% & 50.69 \% & 49.14 \% &\\
\cline{3-6}
& & 0.5 - 0.25 & 78.06 \% & 62.87 \% & 63.16 \% &\\
\cline{2-3}
\cline{4-6}
& Orientación & 0.7 - 0.5 & 75.78 \% & 60.69 \% & 60.12 \% &\\
\hline
\caption{Comparativa de los modelos entrenados sobre KITTI.}
\label{tab:Comparativa_de_los_modelos_entrenados_sobre_kitti}
\end{longtable}
\end{center}

Tras la obtención de la comparativa cuantitativa de los modelos en al tabla \ref{tab:Comparativa_de_los_modelos_entrenados_sobre_kitti} se observa como la mejor precisión se obtiene utilizando el modelo PointRCNN y la mayor velocidad de inferencia con el modelo PointPillars.

\subsection{Análisis cuantitativo en nuScenes}
\label{sec:analisis_cuantitativo_en_nuscenes}

La evaluación sobre el dataset nuScenes consta unicamente del modelo CBGS, pero este modelo se utiliza con dos backbone diferentes: uno basado en SECOND y otro en PointPillars.\par
Los modelos entrenados sobre nuScenes se evaluan unicamente sobre el benchmark de detección 3D, dicha evaluación consta no solo del \acs{ap}, como realiza KITTI, sino que también utiliza las siguientes métricas:

\begin{itemize}
\item \textbf{\ac{ate}}: Distancia euclídea en \acs{bev} medido en metros
\item \textbf{\ac{ase}}: Calculado como 1 - \acs{iou} tras alinear el centro y la orientación
\item \textbf{\ac{aoe}}: Ángulo más pequeño entre la predicción y el groundtruth medido en radianes
\item \textbf{\acl{ave}}: Error de la velocidad absoluta en m/s
\item \textbf{\ac{aae}}: Calculado como 1 - \textit{acc}, donde \textit{acc} es la precisión de la clasificación de atributos
\end{itemize}

Para la evaluación general del modelo se define el parámetro \ac{nds} que indica la precisión respecto de todas las métricas calculadas del modelo.

\begin{center}
$NDS = \dfrac{1}{2} - \dfrac{mATE + mASE + mAOE + mATE + mAAE}{10} + \dfrac{mAP}{2}$
\end{center}

Con este método de evaluación general se otorga 5 veces la importancia del resto de métricas al \acs{ap}, al considerarse en nuScenes que es la métrica más importante.

\begin{center}
\begin{longtable}{|c||c|c|c|c|c|c|}
\hline
\textbf{Tipo de objeto}&\textbf{AP}&\textbf{ATE}&\textbf{ASE}&\textbf{AOE}&\textbf{AVE}&\textbf{AAE}\\
\hline
\hline
\endfirsthead
\multicolumn{4}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Tipo de objeto}&\textbf{AP}&\textbf{ATE}&\textbf{ASE}&\textbf{AOE}&\textbf{AVE}&\textbf{AAE}\\
\hline
\endhead
\hline \multicolumn{4}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
Coche& 0.82 & 0.18 & 0.15 & 0.9 & 0.26 & 0.20 \\
\hline
Camión& 0.52 & 0.34 & 0.19 & 0.06 & 0.21 & 0.24 \\
\hline
Bus& 0.67 & 0.35 & 0.18 & 0.04 & 0.38 & 0.26 \\
\hline
Tráiler& 0.37 & 0.52 & 0.21 & 0.28 & 0.18 & 0.18 \\
\hline
Vehículo de construcción& 0.15 & 0.75 & 0.45 & 0.78 & 0.12 & 0.34 \\
\hline
Peatón& 0.78 & 0.16 & 0.28 & 0.39 & 0.24 & 0.09 \\
\hline
Motocicleta& 0.43 & 0.22 & 0.23 & 0.33 & 0.48 & 0.29 \\
\hline
Bicicleta& 0.17 & 0.18 & 0.26 & 0.33 & 0.23 & 0.02 \\
\hline
Cono de tráfico& 0.58 & 0.17 & 0.33 & nan & nan & nan \\
\hline
Barrera& 0.59 & 0.26 & 0.28 & 0.06 & nan & nan \\
\hline
\caption{Análisis por clase de CBGS SECOND Multihead en nuScenes.}
\label{tab:analisis_por_clase_de_cbgs_second_multihead_en_nuscenes}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{|c||c|c|c|c|c|c|}
\hline
\textbf{Tipo de objeto}&\textbf{AP}&\textbf{ATE}&\textbf{ASE}&\textbf{AOE}&\textbf{AVE}&\textbf{AAE}\\
\hline
\hline
\endfirsthead
\multicolumn{7}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Tipo de objeto}&\textbf{AP}&\textbf{ATE}&\textbf{ASE}&\textbf{AOE}&\textbf{AVE}&\textbf{AAE}\\
\hline
\endhead
\hline \multicolumn{7}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
Coche& 0.81 & 0.19 & 0.15 & 0.12 & 0.28 & 0.21 \\
\hline
Camión& 0.50 & 0.35 & 0.19 & 0.09 & 0.22 & 0.24 \\
\hline
Bus& 0.64 & 0.37 & 0.18 & 0.05 & 0.44 & 0.29 \\
\hline
Tráiler& 0.35 & 0.61 & 0.21 & 0.39 & 0.18 & 0.16 \\
\hline
Vehículo de construcción& 0.12 & 0.76 & 0.45 & 0.77 & 0.12 & 0.33 \\
\hline
Peatón& 0.72 & 0.17 & 0.28 & 0.39 & 0.25 & 0.09 \\
\hline
Motocicleta& 0.29 & 0.23 & 0.25 & 0.45 & 0.58 & 0.27 \\
\hline
Bicicleta& 0.06 & 0.19 & 0.27 & 0.50 & 0.25 & 0.04 \\
\hline
Cono de tráfico& 0.47 & 0.18 & 0.33 & nan & nan & nan \\
\hline
Barrera& 0.50 & 0.34 & 0.29 & 0.07 & nan & nan \\
\hline
\caption{Análisis por clase de CBGS PointPillars Multihead en nuScenes.}
\label{tab:analisis_por_clase_de_cbgs_pointpillars_multihead_en_nuscenes}
\end{longtable}
\end{center}

Al utilizar el modelo CBGS para la mejora del sistema de detección en el vehículo T4AC que utiliza el modelo PointPillars, se muestran los resultados del modelo PointPillars proporcionado por nuScenes como baseline para su benchmark de detección. Estos resultados son recogidos del propio ranking de detección al ser una versión modificada para su uso en nuScenes, que usa 10 barridos del \acs{lidar} para la inferencia de las velocidades, se ajusta a las características de intensidad del \acs{lidar} y realiza una detección en los 360º.

\begin{center}
\begin{longtable}{|c||c|c|c|c|c|c|}
\hline
\textbf{Tipo de objeto}&\textbf{AP}&\textbf{ATE}&\textbf{ASE}&\textbf{AOE}&\textbf{AVE}&\textbf{AAE}\\
\hline
\hline
\endfirsthead
\multicolumn{7}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Tipo de objeto}&\textbf{AP}&\textbf{ATE}&\textbf{ASE}&\textbf{AOE}&\textbf{AVE}&\textbf{AAE}\\
\hline
\endhead
\hline \multicolumn{7}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
Coche& 0.68 & 0.28 & 0.16 & 0.20 & 0.24 & 0.36 \\
\hline
Camión& 0.23 & 0.50 & 0.23 & 0.18 & 0.26 & 0.41 \\
\hline
Bus& 0.28 & 0.56 & 0.20 & 0.25 & 0.42 & 0.34 \\
\hline
Tráiler& 0.23 & 0.89 & 0.20 & 0.83 & 0.20 & 0.21 \\
\hline
Vehículo de construcción& 0.04 & 0.89 & 0.49 & 1.26 & 0.11 & 0.15 \\
\hline
Peatón& 0.60 & 0.28 & 0.31 & 0.37 & 0.25 & 0.16 \\
\hline
Motocicleta& 0.27 & 0.36 & 0.29 & 0.79 & 0.63 & 0.64 \\
\hline
Bicicleta& 0.01 & 0.31 & 0.32 & 0.54 & 0.43 & 0.68 \\
\hline
Cono de tráfico& 0.31 & 0.40 & 0.39 & nan & nan & nan \\
\hline
Barrera& 0.39 & 0.71 & 0.30 & 0.08 & nan & nan \\
\hline
\caption{Análisis por clase de PointPillars en nuScenes.}
\label{tab:analisis_por_clase_de_pointpillars_en_nuscenes}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{|c|c|c|c|}
\hline
\textbf{Modelo}&\textbf{Métrica}&\textbf{Resultado}&\textbf{Velocidad}\\
\hline
\hline
\endfirsthead
\multicolumn{4}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Modelo}&\textbf{Métrica}&\textbf{Resultado}&\textbf{Velocidad}\\
\hline
\endhead
\hline \multicolumn{4}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
\multirow{7}{*}{SECOND Multihead (CBGS)}
& mAP & \textbf{0.5066} &
\multirow{7}{*}{9.18 Hz}\\
\cline{2-3}
& mATE & \textbf{0.3126} &\\
\cline{2-3}
& mASE & \textbf{0.2552} &\\
\cline{2-3}
& mAOE & \textbf{0.2625} &\\
\cline{2-3}
& mAVE & \textbf{0.2616} &\\
\cline{2-3}
& mAAE & 0.2031 &\\
\cline{2-3}
& NDS & \textbf{0.6238} &\\
\hline
\multirow{7}{*}{PointPillars Multihead (CBGS)}
& mAP & 0.4474 &
\multirow{7}{*}{\textbf{12.84 Hz}}\\
\cline{2-3}
& mATE & 0.3379 &\\
\cline{2-3}
& mASE & 0.2598 &\\
\cline{2-3}
& mAOE & 0.3156 &\\
\cline{2-3}
& mAVE & 0.2886 &\\
\cline{2-3}
& mAAE & \textbf{0.2025} &\\
\cline{2-3}
& NDS & 0.5832 &\\
\hline
\multirow{7}{*}{PointPillars}
& mAP & 0.3050 &
\multirow{7}{*}{37.29 Hz}\\
\cline{2-3}
& mATE & 0.5169 &\\
\cline{2-3}
& mASE & 0.2900 &\\
\cline{2-3}
& mAOE & 0.4950 &\\
\cline{2-3}
& mAVE & 0.3163 &\\
\cline{2-3}
& mAAE & 0.3675 &\\
\cline{2-3}
& NDS & 0.4539 &\\
\hline
\caption{Comparativa de los modelos entrenados sobre nuScenes.}
\label{tab:Comparativa_de_los_modelos_entrenados_sobre_nuscenes}
\end{longtable}
\end{center}

El modelo PointPillars es claramente superado en nuScenes por los modelos basados en CBGS, por lo que se ve la mejora en precisión que el nuevo sistema de percepción va a recibir.

\subsection{Análisis adicionales}
\label{sec:analisis_adicionales}

Tras el estudio de la precisión y el rendimiento de los modelos, se deciden realizar diferentes estudios de los modelos sobre ambos datasets para: evaluar todos los modelos sobre el mismo dataset, tratar de reducir el tiempo de computo y aumentar la precisión del modelo CBGS.

\subsubsection{Transferencia de modelos basados en Kitti a nuScenes}
\label{sec:ajuste_de_modelos_basados_en_kitti_a_nuscenes}

La evaluación realizada en KITTI para la detección 3D se aplica unicamente en la parte frontal del vehículo para que las cámaras sean capaces de detectar todos los objetos, por ello los modelos entrenados sobre este dataset han sido entrenados para que su detección se ajuste unicamente a la parte frontal.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/7_resultados/pointpillars_180_kitti.png}
	\caption{Modelo PointPillars sobre KITTI.}
	\label{fig:Modelo_pointpillars_sobre_kitti}
\end{figure}

Con los modelos basados en Deep Learning se ha modificado el entrada de la red para que permita una detección en 360º sin necesidad de un reentrenamiento, todo ello con una buena precisión. El problema es que para el uso de estos modelos en 360º de la mejor forma, sería necesaria la información de todo el entorno del vehículo para el entrenamiento de los modelos, cosa que no se puede hacer con KITTI.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{figures/7_resultados/pointpillars_360_kitti.png}
	\caption{Modelo PointPillars sobre KITTI con detección 360º.}
	\label{fig:Modelo_pointpillars_sobre_kitti_con_deteccion_360}
\end{figure}

La evaluación de todos los modelos sobre el mismo dataset sería lo más conveniente, pero al necesitar un modelo 360º para la implementación en el vehículo T4AC, se necesitaría trabajar sobre nuScenes. Para ello se modifican los datos de entrada junto con el pipeline del modelo para poder correr y entrenar los modelos de KITTI sobre nuScenes.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{figures/7_resultados/pointpillars_360_nuscenes.png}
	\caption{Modelo PointPillars sobre nuScenes con detección 360º.}
	\label{fig:Modelo_pointpillars_sobre_nuscenes_con_deteccion_360}
\end{figure}

El problema del entrenamiento sobre nuScenes es la cantidad de clases que tiene y que el modelo debe de ser capaz de detectar. El modelo sin reentrenar no funciona de forma correcta ya que no tiene los mismos niveles de intensidad del \acs{lidar} además de que nuScenes utiliza un \acs{lidar} de 32 haces en vez de 64 como se tiene en KITTI.\par
Tras el reentrenamiento probando con múltiples configuraciones de parámetros y de capas congeladas, se llega al resultado de que solo se produce un aprendizaje para la clase coche, ya que esta es la más abundante en el dataset, mientras que el resto no terminan de funcionar o funcionan de forma peor, como sería el caso de los peatones que no son detectados al tener la mitad de puntos que el dataset sobre el que fue entrenado, además de ser confundidos con conos de tráfico. Por lo que tanto se concluye que debido a las pobres detecciones obtenidas y el uso de un único barrido del \acs{lidar}, lo que se traduce en una incapacidad para la inferencia de las velocidades de los objetos, los modelos propuestos sobre KITTI en nuScenes no se entrenan convenientemente.

\subsubsection{Número de nubes de puntos de entrada en modelos evaluados sobre nuScenes}
\label{sec:numero_de_pcl_de_entrada_en_modelos_evaluados_sobre_nuscenes}

En el dataset nuScenes se recomienda el uso de múltiples barridos del \acs{lidar}, para de esta manera obtener una mayor nube de puntos aprovechando su tasa de 20 Hz y para poder detectar las velocidades de los objetos del entorno, en concreto se recomienda un uso de 10 barridos.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/7_resultados/frames_per_sweep.png}
	\caption{Análisis del rendimiento de los modelos basados en CBGS según el número de barridos.}
\label{fig:Analisis_del_rendimiento_de_los_modelos_basados_en_cbgs_segun_el_numero_de_barridos}
\end{figure}

Basados en el principio de que a partir de cada uno de los vóxeles se extraen las características, se decide estudiar la ganancia en rendimiento de los modelos CBGS al utilizar menos barridos, lo cual a su vez disminuirá la precisión del modelo.\par
La figura \ref{fig:Analisis_del_rendimiento_de_los_modelos_basados_en_cbgs_segun_el_numero_de_barridos} muestra el rendimiento sobre todo el dataset de nuScenes, mostrando la mediana, cuartiles y deciles de la velocidad de inferencia de los modelos. Se puede ver de esta manera que a partir del uso único de 3 barridos se consigue una mejora en el rendimiento, mientras que con el aumento hasta 10, la velocidad de inferencia no se mejora. Por otra parte revisando los deciles del rendimiento se observa que unicamente PointPillars Multihead consigue un rendimiento siempre superior a los 10 Hz, requisito indispensable para la implementación el proyecto Techs4AgeCar.

\begin{center}
\begin{longtable}{|c|c|c|c|c|c|c|c|}
\hline
\textbf{Barridos}&\textbf{mATE}&\textbf{mASE}&\textbf{mAOE}&\textbf{mAVE}&\textbf{mAAE}&\textbf{mAP}&\textbf{NDS}\\
\hline
\hline
\endfirsthead
\multicolumn{8}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Barridos}&\textbf{mATE}&\textbf{mASE}&\textbf{mAOE}&\textbf{mAVE}&\textbf{mAAE}&\textbf{mAP}&\textbf{NDS}\\
\hline
\endhead
\hline \multicolumn{8}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
1 & 0.34 & 0.26 & 0.53 & 1.56 & 0.33 & 0.35 & 0.43 \\
\hline
2 & 0.33 & 0.26 & 0.33 & 0.82 & 0.22 & 0.43 & 0.52 \\
\hline
3 & 0.32 & 0.26 & 0.29 & 0.54 & 0.21 & 0.47 & 0.57 \\
\hline
4 & 0.32 & 0.26 & 0.28 & 0.43 & 0.21 & 0.49 & 0.60 \\
\hline
5 & 0.32 & 0.26 & 0.27 & 0.36 & 0.20 & 0.50 & 0.61 \\
\hline
6 & 0.31 & 0.26 & 0.26 & 0.33 & 0.20 & 0.50 & 0.62 \\
\hline
7 & 0.31 & 0.26 & 0.26 & 0.30 & 0.21 & 0.51 & 0.62 \\
\hline
8 & 0.31 & 0.25 & 0.26 & 0.28 & 0.21 & 0.51 & 0.62 \\
\hline
9 & 0.31 & 0.25 & 0.27 & 0.27 & 0.24 & 0.51 & 0.62 \\
\hline
10 & 0.31 & 0.26 & 0.26 & 0.26 & 0.20 & 0.51 & 0.62 \\
\hline
\caption{Análisis de la precisión de SECOND Multihead según el número de barridos.}
\label{tab:Analisis_de_la_precision_de_second_multihead_segun_el_numero_de_barridos}
\end{longtable}
\end{center}

\begin{center}
\begin{longtable}{|c|c|c|c|c|c|c|c|}
\hline
\textbf{Barridos}&\textbf{mATE}&\textbf{mASE}&\textbf{mAOE}&\textbf{mAVE}&\textbf{mAAE}&\textbf{mAP}&\textbf{NDS}\\
\hline
\hline
\endfirsthead
\multicolumn{8}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Barridos}&\textbf{mATE}&\textbf{mASE}&\textbf{mAOE}&\textbf{mAVE}&\textbf{mAAE}&\textbf{mAP}&\textbf{NDS}\\
\hline
\endhead
\hline \multicolumn{8}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
1 & 0.35 & 0.27 & 0.63 & 1.74 & 0.33 & 0.31 & 0.39 \\
\hline
2 & 0.36 & 0.26 & 0.42 & 0.89 & 0.23 & 0.36 & 0.47 \\
\hline
3 & 0.35 & 0.26 & 0.37 & 0.61 & 0.21 & 0.39 & 0.52 \\
\hline
4 & 0.35 & 0.26 & 0.34 & 0.47 & 0.21 & 0.41 & 0.54 \\
\hline
5 & 0.34 & 0.26 & 0.34 & 0.39 & 0.20 & 0.42 & 0.56 \\
\hline
6 & 0.34 & 0.26 & 0.33 & 0.36 & 0.20 & 0.43 & 0.57 \\
\hline
7 & 0.34 & 0.26 & 0.33 & 0.33 & 0.20 & 0.44 & 0.57 \\
\hline
8 & 0.34 & 0.26 & 0.33 & 0.31 & 0.20 & 0.44 & 0.58 \\
\hline
9 & 0.34 & 0.26 & 0.32 & 0.30 & 0.20 & 0.45 & 0.58 \\
\hline
10 & 0.34 & 0.26 & 0.32 & 0.29 & 0.20 & 0.45 & 0.58 \\
\hline
\caption{Análisis de la precisión de PointPillars Multihead según el número de barridos.}
\label{tab:Analisis_de_la_precision_de_pointpillars_multihead_segun_el_numero_de_barridos}
\end{longtable}
\end{center}

El uso de 2 barridos con SECOND Multihead no supera en precisión a PointPillars Multihead con los 10 barridos por lo que este modelo sería descartado. Por otra parte en el caso de PointPillars Multihead sería recomendable el uso de 8 barridos en vez de 10 ya que la precisión no se ve apenas reducida, mientras que el rendimiento consigue una mejora de poco más del 4\%, que aunque sea poco puede definir en un caso extremo si una nube de puntos es analizada o no por la velocidad de inferencia del modelo.

\subsubsection{Tamaño del vóxel en modelos basados en redes neuronales}
\label{sec:tamaño_del_voxel_en_modelos_basados_en_redes_neuronales}

Basándose en múltiples papers que utilizan la reducción del tamaño del vóxel para el aumento de la precisión a costa del rendimiento, como ocurre con el modelo PointPillars+ \cite{pointpainting} junto con otras técnicas, se decide entrenar el modelo PointPillars Multihead ya que es el utilizando actualmente en el proyecto Techs4AgeCar y permite usar un tamaño de vóxel menor. De esta forma se espera que mejore la precisión del modelo, a la vez que se reduce la distancia de detección, la cual puede empeorar ya que se trabaja con un \acs{lidar} en el vehículo T4AC de 16 haces.

\begin{center}
\begin{longtable}{|c|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{Modelo}&\textbf{Tamaño de vóxel}&\textbf{Tamaño de la nube de puntos}&\textbf{NDS}\\
\hline
\hline
\endfirsthead
\multicolumn{10}{c}%
{\tablename\ \thetable\ -- \textit{Continua en la página anterior}} \\
\hline
\textbf{Modelo}&\textbf{Tamaño de vóxel}&\textbf{Tamaño de la nube de puntos}&\textbf{NDS}\\
\hline
\endhead
\hline \multicolumn{10}{r}{\textit{Continua en la próxima página}} \\
\endfoot
\endlastfoot
Modelo base & [0.2, 0.2, 8.0] & [102.4, 102.4, 8.0] & 0.5832 \\
\hline
Modelo base & [0.2, 0.1, 8.0] & [102.4, 51.2, 8.0] & 0.2391 \\
\hline
Modelo base + 5 epochs & [0.2, 0.1, 8.0] & [102.4, 51.2, 8.0] & 0.3550 \\
\hline
\caption{Análisis de la precisión de PointPillars Multihead según el tamaño del voxel.}
\label{tab:Analisis_de_la_precision_de_pointpillars_multihead_segun_el_tamano_del_voxel}
\end{longtable}
\end{center}

Al utilizar el modelo base de PointPillars Multihead reduciendo el tamaño de vóxel para que se centre el análisis de la escena principalmente en la parte frontal y trasera del vehículo, se obtiene una precisión mucho menor, la cual no es utilizable de la misma manera que disminuyendo el número de barridos. Se ha reentrenado la red con 5 iteraciones para mejorar la precisión, tras esto se observa una mejora sustancial en la precisión de las detecciones del modelo. Como se ha visto, el problema puede encontrarse en el ajuste de los tamaños de los objetos a detectar en función del tamaño de los vóxeles del modelo base. La solución sería el entrenamiento de la red de nuevo para solucionar este problema, pero para cada iteración en el entrenamiento de esta red en nuScenes han sido necesarias entre 10 y 12 horas, por lo que resulta inviable con el hardware que se dispone.

\section{Análisis sobre el simulador CARLA}
\label{sec:analisis_sobre_el_simulador_carla}

El análisis de los modelos en los datasets sobre los que han sido entrenados solo muestra la precisión dentro de estos. Con datos provenientes de otras fuentes como sería el simulador CARLA, se analiza cómo de buenos son estos modelos en otros entornos para su posterior implementación en el vehículo T4AC el cual incorpora un \acs{lidar} diferente al utilizado en los datasets.
En los resultados obtenidos se ha simulado un vehículo con un \acs{lidar} de 32 haces con una velocidad de barrido de 20 Hz.

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|c|c|} 
		\hline
		\textbf{Parámetro} & \textbf{Valor}\\ 
		\hline
		Posición & [0, 0, 1.95] m\\ 
		\hline
		Distancia & 50 m\\
		\hline
		Haces & 32\\
		\hline
		Puntos por segundo & 320000\\
		\hline
		Campo de visión & 2º/-26.8º\\
		\hline
		\end{tabular}
		\caption{Parámetros del LiDAR en CARLA.}
		\label{tab:Parametros_del_lidar_en_carla}
	\end{center}
\end{table}

\subsection{Análisis cualitativo del modelo clásico en CARLA}
\label{sec:analisis_cualitivo_del_modelo_clasico_en_carla}

El estudio realizado en el capítulo \ref{cha:sistemas_clasicos_de_percepcion_con_lidar} desemboca en la implementación en un sistema basado en técnicas clásicas que fue presentado en el capítulo \ref{sec:implementacion_del_sistema_clasico_basado_en_lidar}. Dicho sistema ha sido construido como un nodo de \acs{ros} en C++ que tiene de entrada la nube de puntos del simulador y publica las detecciones. Este sistema ha sido probado en múltiples escenarios para su análisis cualitativo.

\begin{figure}[H]
  \begin{subfigure}[t]{.325\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/classic_algorithm_pedestrian_crossing_simulation.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.325\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/classic_algorithm_uwubag_simulation_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.325\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/classic_algorithm_uwubag_simulation_2.jpg}
  \end{subfigure}
\caption{Modelo clásico en CARLA.}
\label{fig:Modelo_clasico_en_carla}
\end{figure}

La velocidad de inferencia de este sistema es de 13.14 milisegundos de media, teniendo como funciones más demandantes: la aplicación del algoritmo \acs{ransac} 3D con 9.57 milisegundos y la función de clustering basada en KD-tree con 2.14 milisegundos, esto resulta en un sistema con una capacidad de inferencia de 76 Hz.\par
El funcionamiento de este algoritmo como se ve en la figura \ref{fig:Modelo_clasico_en_carla} es bastante bueno, con pocos falsos positivos. El mayor problema que tiene dicho algoritmo es la incapacidad de detectar otro tipo de objeto que no sean coches, ya que si tienen que ser detectados los peatones, aparecerían problemas de muchos falsos positivos con farolas, semáforos, etc. La diferenciación de cada objeto en función de su clase no es posible en este método ya que aunque se analizase el tamaño de los objetos se encontrarían muchos fallos en función del número de puntos incidentes sobre cada objeto, ya que farolas, arbustos, conos, semáforos y peatones serían incluidos en el mismo grupo.

\subsection{Análisis cualitativo de Pointpillars Multihead en CARLA}
\label{sec:analisis_cualitativo_de_cbgs_en_carla}

El modelo finalmente implementado en el proyecto ha sido PointPillars Multihead, este modelo es probado en simulación antes de su prueba en el vehículo T4AC. Uno de los problemas principales que se encuentran con el uso en simulación es la intensidad simulada del \acs{lidar}, como se explica en el capítulo \ref{sec:funcionamiento_del_lidar_en_carla}, esto provoca que se use una intensidad fija de 0 en todos los puntos.

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_pedestrian_crossing_simulation_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_pedestrian_crossing_simulation_2.jpg}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_uwubag_simulation_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_uwubag_simulation_2.jpg}
  \end{subfigure}
\caption{PointPillars Multihead en CARLA.}
\label{fig:Pointpillars_multihead_en_carla}
\end{figure}

Las pruebas se han desarrollado sobre un mapa creado dentro del grupo RobeSafe que simula la Universidad de Alcalá, en el que se ha colaborado, y en un mapa proporcionado por CARLA. Este modelo ya no solo ajusta mejor las bounding boxes de los coches sino que detecta a los peatones del escenario respecto del modelo clásico.\par
Aún obteniendo estos resultados tan buenos hay que tener en cuenta que la intensidad no se utiliza, por lo que la asociación de objetos entre barridos es más difícil. Durante la implementación de dicho modelo se ha detectado un fallo en CARLA en el que el frame del \acs{lidar} se encuentra vibrando, lo cual es el culpable de la mala inferencia de velocidad obtenida, por lo que ha sido reportado dicho error. Se observa además que debido a este problema del simulador, se obtiene una precisión mucho mejor con el vehículo parado o a velocidades bajas.

\subsubsection{Comparativa con PointPillars en CARLA}
\label{sec:comparatica_con_pointpillars_en_carla}

Para ver la mejora en precisión de la implementación del modelo PointPillars Multihead sobre la arquitectura del proyecto Techs4AgeCar respecto de la anterior implementación de PointPillars se realiza el siguiente análisis cualitativo sobre CARLA, en el que se muestran las mismas escenas que las vistas en la figura \ref{fig:Pointpillars_multihead_en_carla}

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_pedestrian_crossing_simulation_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_pedestrian_crossing_simulation_2.jpg}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_uwubag_simulation_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_uwubag_simulation_2.jpg}
  \end{subfigure}
\caption{PointPillars en CARLA.}
\label{fig:Pointpillars_en_carla}
\end{figure}

La implementación actual no solo mejora como se ve claramente en la precisión de las detecciones de los coches al producir menos falsos positivos, sino que ahora también se detectar peatones, cosa que en la anterior implementación esto no era posible.


\subsection{Análisis cuantitativo de Pointpillars Multihead en CARLA}
\label{sec:analisis_cuantitativo_de_cbgs_en_carla}

Haciendo uso del \acs{ad_devkit} desarrollado en este TFG, se evalúa el modelo PointPillars Multihead. Este kit de evaluación es capaz de evaluar las clases definidas en \acs{ros} por CARLA, como son: peatón, bicicleta, coche, camión, barrera, señal u otro vehículo, dichas clases no coinciden directamente con las detectadas por el modelo por lo que se pueden reducir las clases detectadas. El mayor problema surge cuando se ve que CARLA identifica todos los vehículos que no son peatones como coches y además se ha observado que al grabar un rosbag con toda la información del entorno sobre la que evaluar, \acs{ros} no es capaz de guardar toda esta información en tiempo real, lo cual produce que las marcas de tiempo se encuentren parcialmente desplazadas. Esto impide la asociación con los peatones al tener un \acs{iou} muy pequeño o nulo por la diferencia entre los tiempos de la información de los sensores y de los objetos del entorno.\par
El \acs{ad_devkit} para la generación de los datos de evaluación utiliza un rosbag que contiene la información de los sensores y del entorno necesaria, con esto se obtiene el groundtruth con el que se evalúa el modelo. Para ello se han utilizado dos rosbag creados en el grupo RobeSafe que son usados para la evaluación cualitativa y ambos rosbag son de 30 segundos aproximadamente. Al utilizar grabaciones de tan corta duración se obtiene métricas diferentes pero que no se ven afectados apenas del problema de \acs{ros} con los retrasos en las marcas de tiempo.

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/ad_devkit_give_way.png}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/ad_devkit_pedestrian_crossing.png}
  \end{subfigure}
  \caption{Curvas de precision-recall para la clase coche de PointPillars Multihead en CARLA.}
  \label{tab:curvas_de_precision_reacall_para_coches_de_pointpillars_multihead_en_carla}
\end{figure}

\begin{table}[H]
\begin{subfigure}[b]{0.48\textwidth}
\centering
\begin{tabular}{|c|c|c|}
		\hline
		\textbf{AP}&\textbf{mIoU}&\textbf{mAVE}\\
		\hline
		0.34&0.49&1.49\\
		\hline
\end{tabular}
\end{subfigure}
\hspace{\fill}
\begin{subfigure}[b]{0.48\textwidth}
\centering
\begin{tabular}{|c|c|c|}
		\hline
		\textbf{AP}&\textbf{mIoU}&\textbf{mAVE}\\
		\hline
		0.37&0.48&0.79\\
		\hline
\end{tabular}
\end{subfigure}
\caption{Métricas para la clase coche de PointPillars Multihead en CARLA.}
\label{tab:curva_de_precision_reacall_para_coches_de_pointpillars_multihead_en_carla}
\end{table}

Con estas métricas se obtiene una precisión aproximada de la clase coche, la cual es el principal objeto a detectar que se va a utilizar en el sistema que usa el modelo PointPillars Multihead. Este es por tanto el rendimiento actual del \acs{ad_devkit} para la evaluación de objetos 3D debido a las limitaciones con \acs{ros} y CARLA.

\section{Análisis sobre el vehículo T4AC}
\label{sec:analisis_sobre_el_vehiculo_t4ac}

Tras una evaluación en CARLA de la implementación realizada, se evalúa en el vehículo T4AC la precisión del modelo implementado para realizar la detección 3D con \acs{lidar}. Teniendo en cuenta que el modelo se ejecuta en el portátil de abordo del vehículo, se espera un rendimiento muy similar al obtenido previamente.\par
El análisis por tanto se produce en el campus de la Universidad de Alcalá donde diversos coches aparecen en ambos sentidos, se producen adelantamientos y aparecen gran cantidad de árboles lo cual puede producir múltiples falsos positivos.

\subsection{Análisis cualitativo de Pointpillars Multihead sobre el vehículo T4AC}
\label{sec:analisis_cualitativo_de_cbgs_sobre_el_vehiculo_t4ac}

Al no poder evaluar de forma cuantitativa la precisión, se analizan de forma cualitativa los resultados obtenidos de la prueba con la nueva implementación en el vehículo T4AC.

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_overtaking_real_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_overtaking_real_2.jpg}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_overtaking_real_3.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_multihead_overtaking_real_4.jpg}
  \end{subfigure}
\caption{PointPillars Multihead en el vehículo T4AC.}
\label{fig:Pointpillars_multihead_en_el_vehiculo_t4ac}
\end{figure}

Tras el ajuste para la detección de unicamente ciertas clases, se puede observar una precisión muy buena donde todos los coches cercanos al propio vehículo son detectados, incluso en situaciones donde hay coches con muy pocos puntos al ser ocluidos por múltiples árboles, el sistema es capaz de detectarlos. Aún trabajando en un sistema real donde hay muchos puntos de colisión con árboles, con los ajustes realizados no se obtienen apenas falsos positivos lo cual es un gran beneficio para su uso en otras capas del proyecto Techs4AgeCar, aunque la detección de objetos pequeños como conos o peatones sigue produciendo falsos positivos debido a que se tiene la mitad de puntos en la nube respecto de las nubes de puntos utilizadas en el entrenamiento del modelo.

\subsubsection{Comparativa con PointPillars sobre el vehículo T4AC}
\label{sec:comparatica_con_pointpillars_sobre el vehículo T4AC}

El mismo recorrido con el sistema que integra el modelo PointPillars Multihead ha sido integrado en el anterior sistema del proyecto que incorpora el modelo Pointpillars, de esta manera se pueden observar las mejoras que el nuevo sistema implementado en este TFG ha aportado al proyecto del grupo RobeSafe. Para ello se muestran en la figura \ref{fig:Pointpillars_en_el_vehiculo_t4ac} los mismos instantes de tiempo que en la figura \ref{fig:Pointpillars_multihead_en_el_vehiculo_t4ac} para de esta manera resaltar la mejora en la precisión del nuevo sistema de detección.

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_overtaking_real_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_overtaking_real_2.jpg}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_overtaking_real_3.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/pointpillars_overtaking_real_4.jpg}
  \end{subfigure}
\caption{PointPillars en el vehículo T4AC.}
\label{fig:Pointpillars_en_el_vehiculo_t4ac}
\end{figure}

La ventaja que se tenía antes con este modelo es la ejecución sobre la NVIDIA Jetson AGX Xavier incorporada en el vehículo T4AC, lo cual aligeraba la carga de trabajo del portátil que se lleva a bordo. Pero de la misma manera que se veía en el simulador CARLA, con el sistema previo al implementado en este Trabajo Fin de Grado se obtenían multitud de falsos positivos, además de que no es capaz de detectar tantos vehículos en situaciones complejas como aquellos ocluidos parcialmente por árboles. Por lo que el trabajo de detección 3D con \acs{lidar} de este TFG ha servido para mejorar el sistema de percepción del vehículo como ha quedado validado en múltiples escenarios.

\subsection{Análisis cualitativo del sistema de fusión sensorial sobre el vehículo T4AC}
\label{sec:analisis_cualitativo_del_sistema_de_fusion_sensorial_sobre_el_vehiculo_t4ac}

Los sistemas de detección basados en \acs{lidar} tienen el inconveniente de la cantidad de falsos positivos que producen al no tener la información suficiente para hallar los objetos del entorno de una forma sencilla, mientras que gracias a este sensor se consigue un ajuste muy bueno de las bounding boxes entorno a los objetos. Por otra parte los sistemas de detección basados en cámara monocular ofrecen un muy buen reconocimiento de los objetos en un entorno 2D, mientras que no son capaces de obtener detecciones 3D muy precisas.\par
Basado en estas características, se consiguen utilizar las detecciones 3D aproximadas provenientes del sistema basado en cámara, mientras que se aprovecha del sistema basado en \acs{lidar} para su ajuste.

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/sensor_fusion_lidar_camera_1.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/sensor_fusion_1.jpg}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/sensor_fusion_lidar_camera_2.jpg}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/7_resultados/sensor_fusion_2.jpg}
  \end{subfigure}
\caption{Fusión sensorial en el vehículo T4AC.}
\label{fig:Fusion_sensorial_en_el_vehiculo_t4ac}
\end{figure}

En la figura \ref{fig:Fusion_sensorial_en_el_vehiculo_t4ac} se muestran las detecciones producidas por el sistema de fusión sensorial, donde en las imágenes de la izquierda se muestran las detecciones de los sistemas de cámara y \acs{lidar}, siendo las detecciones rojas aquellas producidas por la cámara y las detecciones azules las generadas por el sistema basado en \acs{lidar}. Por otra parte a la derecha se muestra el resultado de la fusión sensorial como detecciones de color negro.\par
Se puede observar como las detecciones de la cámara solo se encuentran en la parte frontal y las producidas por el \acs{lidar} alrededor del vehículo, esto consigue un sistema donde se mejoran las detecciones frontales, ya que es necesario una detección en ambos sistemas sobre un objeto para darse como correcta dicha detección.\par
En cuanto a la velocidad de inferencia para el modelo CBGS, se espera una velocidad de inferencia de 8.68 Hz en el portátil de abordo del vehículo T4AC, que consta de una tarjeta gráfica GTX 1070 Mobile, dicho sistema sustituye al sistema basado en PointPillars ejecutado sobre una NVIDIA Jetson AGX Xavier, que obtiene una frecuencia en la inferencia de 7.3 Hz.
