\chapter{Sistemas clásicos de percepción con LiDAR}
\label{cha:sistemas_clasicos_de_percepcion_con_lidar}

\begin{FraseCelebre}
  \begin{Frase}
    El placer más noble es el júbilo de comprender.
  \end{Frase}
  \begin{Fuente}
    Leonardo da Vinci
  \end{Fuente}
\end{FraseCelebre}

\noindent
Mientras que se tienen múltiples tipos de técnicas de percepción tanto clásicas como basadas en Deep Learning, el uso de técnicas clásicas utilizando unicamente \acs{lidar} no abundan, por lo que se presentan las técnicas estudiadas e implementadas en el simulador CARLA para la detección de los objetos del entorno.

\section{Voxelización}
\label{sec:voxelizacion}

Las nubes de puntos generadas por el \acs{lidar} pueden ser de hasta 1.300.000 puntos por segundo en un \acs{lidar} de 64 haces \cite{velodyne_hdl_64} lo que implicaría el análisis de una gran cantidad de datos en tiempo real lo que puede no ser muy viable ya que se tiene una capacidad de computo limitada en un vehículo.\par
Para ello se utiliza la voxelización, esta no solo se utiliza en sistemas de percepción, sino que también es utilizada en imágenes volumétricas de ámbito médico, para la representación del terreno o en el pipeline gráfico de un ordenador. Esta técnica trata de reducir la cantidad de datos en memoria a la vez que reduce el computo al reducir la resolución de la escena. Por lo que se puede entender como un proceso de discretización del entorno.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.55\textwidth]{figures/3_sistemas_clasicos_de_percepcion/entorno_voxelizado.png}
	\caption{Entorno 3D voxelizado.}
	\label{fig:Entorno_3d_voxelizado}
\end{figure}

Trabajando con nubes de puntos, la voxelización sigue los siguientes pasos:
\begin{enumerate}
	\item Definición del tamaño del vóxel, lo que sería un vector tridimensional.
	\item A partir del tamaño del vóxel se divide la escena en un conjunto de ortoedros u vóxeles.
	\item Si se encuentra un punto del \ac{lidar} dentro de un vóxel este de activa
\end{enumerate}
\par
Esta técnica como se verá en el capítulo \ref{cha:sistemas_de_percepcion_con_lidar_basados_en_deep_learning}, también se utiliza en diversos modelos basados en Deep Learning, esto se hace para trabajar de forma similar a lo que sería la estructura de una imagen que se encuentra compuesta por píxeles en vez de por vóxeles.

\section{RANSAC-3D}
\label{sec:ransac_3d}

Para la detección de los objetos del entorno no es necesaria la información de los puntos que inciden en el suelo, por lo que una de las técnicas utilizadas para la selección del plano perteneciente al suelo es \ac{ransac}-3D.\par
El algoritmo \acs{ransac} \cite{ransac} tiene una funcionalidad similar a la regresión linear, ambos algoritmos a partir de un conjunto de datos hayan la relación lineal entre dos características. La creación de este algoritmo tenía como finalidad el ajuste de datos experimentales, el uso en el análisis de escenas y la generación automática de mapas.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/3_sistemas_clasicos_de_percepcion/ransac.png}
	\caption{Aplicación de RANSAC para detección de outliers.}
	\label{fig:Aplicacion_de_ransac_para_deteccion_de_outliers}
\end{figure}

La idea principal del algoritmo \acs{ransac} es la generación de rectas a partir de 2 o más puntos para aceptar como la mejor recta aquella que contenga más puntos entre un límite seleccionado, y esto es repetido un número arbitrario de veces. Esta recta será la que contenga los puntos asumidos como normales o inliers, y el resto de puntos son asumidos como anómalos o outliers. La función completa utiliza el siguiente algoritmo \ref{alg:Algoritmo_ransac}.

\newpage

\begin{algorithm}[H]
	\SetAlgoLined
	\begin{algorithmic}
		\Input
		\Desc{data}{Conjunto de observaciones}
		\Desc{model}{Modelo que explica las observaciones}
		\Desc{n}{Mínimo número de puntos necesarios para estimar un modelo}
		\Desc{k}{Número de iteraciones del algoritmo}
		\Desc{t}{Valor límite que indica que puntos se encuentran bien estimados}
		\Desc{d}{Número de puntos cercanos que asegura que el modelo sea válido}
		\EndInput
		\Output
		\Desc{bestFit}{Parámetros del modelo que ajustan de mejor manera a los datos}
		\EndOutput
	\end{algorithmic}
 	$iterations \leftarrow$ 0\\
 	$bestFit \leftarrow$ null\\
 	$bestError \leftarrow \infty$\\
 	
 	\While{$iterations < k$}{
  		$maybeInliers \leftarrow n$ puntos seleccionados aleatoriamente\\
  		$maybeModel \leftarrow$ modelo que se ajusta a $maybeInliers$\\
  		$alsoInliers \leftarrow$ set vacío\\
  		\For{cada punto que no se encuentre en $maybeInliers$}{
  			\If{error de ajustar el punto a $maybeModel < t$}{
  				añadir punto a $alsoInliers$\\
  			}
  		}
  		\If{número de puntos en $alsoInliers > d$}{
  			$betterModel \leftarrow$ parámetros del modelo sobre el que han sido ajustados los puntos de $maybeInliers$ y $alsoInliers$\\
  			$thisErr \leftarrow$ medida de como de bien han sido ajustado los puntos\;
  			\If{$thisErr < bestErr$}{
  				$bestFit \leftarrow betterModel$\\
  				$bestErr \leftarrow thisErr$\\
  			}
  		}
  		$iterations \leftarrow iterations +$ 1\;
 	}
 	\caption{Algoritmo RANSAC}
 	\label{alg:Algoritmo_ransac}
\end{algorithm}

En el caso de las nubes de puntos que devuelve el \acs{lidar}, se trabaja en un entorno tridimensional, por lo que no funciona de la misma manera dicho algoritmo, se utiliza una variación, \acs{ransac}-3D como se ve en la figura \ref{fig:Aplicacion_de_ransac_3d}, que en vez de trabajar con datos en 2D se trabajan en 3D, por lo que se pasa de ajustar un modelo lineal se ajusta un modelo como plano, por lo que como mínimo se necesitan tres puntos para generar un posible modelo ya que es el mínimo número de puntos para generar un plano, el resto funciona de forma similar definiendo el límite de distancia, iteraciones, etc.\par
Como se se ha explicado, los resultados suelen ser similares a una regresión linear en un entorno bidimensional, pero en este caso no sería del todo cierto, ya que el plano que abarca más puntos suele ser en la mayoría de los casos el correspondiente al suelo. Esto implica una modificación de la regresión linear a las tres dimensiones, esto es una regresión ajustada como un plano, esta generara en la mayoría de las situaciones un plano que se encuentra por encima del suelo, ya que trataría de minimizar una métrica de error al plano (distancia euclídea, manhattan, minkowski, hamming, etc.), por lo que los objetos de la escena levantarían el plano para minimizar el error de este a los puntos correspondientes a los objetos.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.35\textwidth]{figures/3_sistemas_clasicos_de_percepcion/ransac_3d.jpg}
	\caption{Aplicación de RANSAC-3D.}
	\label{fig:Aplicacion_de_ransac_3d}
\end{figure}

De forma comparativa al algoritmo \acs{ransac}-3D, este genera un plano ajustándose a la mayoría de los puntos de la escena, anotando como inliers aquellos puntos pertenecientes al suelo y dejando el resto de puntos que colisionan con el entorno como outliers, por lo que dicho algoritmo \acs{ransac} es el utilizado para la tarea de filtrado de la sección de la nube de puntos que colisiona con el suelo de la escena.

\section{KD-tree}
\label{sec:kd_tree}

Tras la eliminación del suelo en la nube de puntos podemos encontrarnos con que los diferentes objetos del entorno se encuentran separados, ya que el suelo era el elemento unificador de la mayoría de puntos de la escena. Teniendo en cuenta esto, es necesario el uso de una técnica que sea capaz de agrupar los puntos más cercanos por distancia, ya que si se hace comprobando cada punto con el resto se obtendría una complejidad de $O(n²)$.\par
Teniendo en cuenta el coste computacional de los algoritmos de clustering y al trabajar con tantos puntos, alrededor de 1.000.000 por segundo y sabiendo que un \acs{lidar} suele trabajar a 10 Hz, es muy recomendable aplicar una voxelización si no se aplicó previamente en la eliminación de los puntos incidentes en el suelo.\par
Para el clustering, se podría utiliza el algoritmo \ac{knn}, pero esto produciría clústeres no válidos al encontrarse objetos con pocos vóxeles o con demasiados, lo que produciría clústeres incompletos y otros mal formados sino se tiene en cuenta una distancia máxima entre vóxeles.\par
El KD-tree \cite{kd_tree} es una estructura de datos que con un eficiente uso de memoria, es capaz de hacer búsquedas en un entorno K dimensional con una complejidad media de $O(\log n)$, esto lo convierte en una gran estructura para trabajar con datos en un entorno tridimensional, como es el caso de las nubes de puntos o de vóxeles. Un KD-tree tiene una estructura similar a un árbol binario, la eficiencia de la estructura radica en la ordenación del mismo, donde en cada altura del árbol se ordena según una dimensión iterativamente.\par
Antes de analizar en profundidad la estructura KD-tree, es necesario comprender los árboles binarios, tanto su uso, como su utilidad. Los árboles binarios son una estructura de datos donde cada nodo tiene otros dos nodos hijos, referidos como hijo izquierdo e hijo derecho. La utilidad de la estructura radica en la forma en la que se pueden guardar los datos, mientras que para buscar un valor en una lista, es necesario iterar por todos ellos o hasta que se encuentre con una complejidad máxima de $O(n)$, lo que hace que un KD-tree tenga una complejidad máxima de $O(\log_2 n)$.

\newpage

\begin{algorithm}[H]
	\SetAlgoLined
	\begin{algorithmic}
		\Input
		\Desc{tree}{Árbol binario ordenado}
		\Desc{key}{Clave del nodo buscado}
		\EndInput
		\Output
		\Desc{node}{Nodo buscado}
		\EndOutput
	\end{algorithmic}
	$node \leftarrow$ null\;
	$currentNode \leftarrow$ nodo raíz de $tree$\\
	\While{currentNode $\neq$ null}{
		\If{clave de $currentNode = key$}{
			$node \leftarrow currentNode$\\
			\textbf{break}\;
		}
		\eIf{clave de $currentNode < key$}
		{
			$currentNode \leftarrow$ hijo derecho de $currentNode$\\
		}{
			$currentNode \leftarrow$ hijo izquierdo de $currentNode$\\
		}
	}
 	\caption{Búsqueda en árbol binario ordenado}
 	\label{alg:Busqueda_en_arbol_binario_ordenado}
\end{algorithm}

En el caso del árbol de la figura \ref{fig:Arbol_binario_ordenado} para buscar el número 7 se utiliza el siguiente procedimiento:
\begin{enumerate}
	\item Se empieza por el nodo con valor 8
	\item Al ser 7 $<$ 8 se pasa al hijo de la izquierda
	\item Como 7 $>$ 3 se salta al hijo de la derecha
	\item Teniendo el nodo con valor 6, siendo menor que 7 se coge el hijo de la derecha
	\item Por último, se llega al nodo con valor 7 requerido
\end{enumerate}
Teniendo 9 nodos solo ha sido necesario analizar 4 nodos que es la peor situación con este árbol.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.35\textwidth]{figures/3_sistemas_clasicos_de_percepcion/binary_tree.png}
	\caption{Árbol binario ordenado.}
	\label{fig:Arbol_binario_ordenado}
\end{figure}

Al contrario que los árboles binarios, un KD-tree es capaz de localizar un número de K dimensiones, por lo que hay una diferencia principal que es la rotación entre la dimensión sobre la que se ordena en cada altura del árbol. Esto produce que la forma de inserción del algoritmo \ref{alg:Insercion_en_KD_tree} y búsqueda sea modificada.

\newpage

\begin{algorithm}[H]
	\SetAlgoLined
	\begin{algorithmic}
		\Input
		\Desc{tree}{KD-tree}
		\Desc{node}{Nodo a introducir}
		\Desc{k}{Número de dimensiones del árbol}
		\EndInput
		\Output
		\Desc{tree}{KD-tree con el nodo introducido}
		\EndOutput
	\end{algorithmic}
	$currentNode \leftarrow$ nodo raíz de $tree$\\
	$depth \leftarrow$ 0\\
	\While{$currentNode \neq$ null}{
		$x \leftarrow depth$ mod $k$\\
		\eIf{valor de $currentNode$ en la dimensión $x <$ valor de $node$ en la dimensión $x$}
		{
			$currentNode \leftarrow$ hijo derecho de $currentNode$\\
		}{
			$currentNode \leftarrow$ hijo izquierdo de $currentNode$\\
		}
		$depth \leftarrow depth +$ 1
	}
	$currentNode \leftarrow node$
 	\caption{Inserción en KD-tree}
 	\label{alg:Insercion_en_KD_tree}
\end{algorithm}

Lo que produce esta forma de guardar los datos en el árbol, es que según se aumenta la profundidad en el árbol, la región de los nodos hijos es cada vez menor, lo que permite una más sencilla agrupación y estudio de los datos por regiones en un entorno K dimensional. Como se ve en la figura \ref{fig:Espacio_bidimensional_dividido_por_un_kd_tree} el espacio bidimensional va siendo dividido por regiones, esto es gracias a que cada nodo divide en dos el espacio sobre el que se encuentran sus hijos, lo cual es una perfecta manera de agrupar los puntos en clústeres utilizando esta estructura, tal y como se detalla en el algoritmo \ref{alg:Cluster_por_distancia_en_KD_tree}

\begin{figure}[H]
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figures/3_sistemas_clasicos_de_percepcion/kd_space.png}
		\caption{Espacio bidimensional dividido por un KD-tree.}
		\label{fig:Espacio_bidimensional_dividido_por_un_kd_tree}
	\end{minipage}\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figures/3_sistemas_clasicos_de_percepcion/kd_tree.png}
		\caption{Estructura de un KD-tree de dos dimensiones.}
		\label{fig:Estructura_de_un_kd_tree_de_dos_dimensiones}
	\end{minipage}
\end{figure}

\newpage

\begin{algorithm}[H]
	\SetAlgoLined
	\begin{algorithmic}
		\Input
		\Desc{points}{Nube de puntos del LiDAR}
		\Desc{id\_node}{Id del punto sobre el que se va a comenzar el clúster}
		\Desc{node}{Nodo sobre el que buscar un clúster}
		\Desc{processed}{Vector de booleanos de tamaño igual al número de puntos}
		\Desc{tree}{KD-tree}
		\Desc{distance}{Distancia máxima a los puntos del clúster}
		\Desc{k}{Número de dimensiones del árbol}
		\EndInput
		\Output
		\Desc{cluster}{Conjunto de los puntos perteneciente al clúster}
		\EndOutput
	\end{algorithmic}
	\SetKwFunction{SearchNodes}{searchNodes}
	\SetKwFunction{Search}{search}
	\SetKwFunction{Proximity}{proximity}
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{\Proximity{$points$, $id\_node$, $node$, $cluster$, $processed$, $tree$, $distance$, $k$}}{
		$processed$[$id\_node$] $\leftarrow$ true\\
		añadir a $cluster$ $points$[$id\_node$]\\
		$indexList \leftarrow$ \Search{$points$[$id\_node$], $tree$, $distance$, $k$} 
		\For{$index$ en $indexList$}{
			\If{$processed$[$index$] $=$ false}{
				\Proximity{$points$, $index$, $cluster$, $processed$, $tree$, $distance$, $k$}
			}
		}
	}
	
	\Fn{\Search{$node$, $tree$, $distance$, $k$}}{
		$indexList \leftarrow$ lista vacía\\
		\SearchNodes{$node$, $tree$, 0, $distance$, $indexList$, $k$}\\
		\Return $indexList$\\
	}
	
	\Fn{\SearchNodes{$node$, $tree$, $distance$, $depth$, $indexList$, $k$}}{
		\If{$tree \neq$ null}{
			\If{distancia entre el nodo raíz de $tree$ y $node < distance$}{
				añadir índice del nodo raíz de $tree$ a $indexList$
			}
		}
		$x \leftarrow depth$ mod $k$\\
		\If{valor de $node$ en la dimensión $x - distance <$ valor del nodo raíz de $tree$ en la dimensión $x$}{
			\SearchNodes{$node$, árbol izquierdo de $tree$, $depth + $1, $distance$, $indexList$, $k$}\\
		}
		\If{valor de $node$ en la dimensión $x + distance >$ valor del nodo raíz de $tree$ en la dimensión $x$}{
			\SearchNodes{$node$, árbol derecho de $tree$, $depth + $1, $distance$, $indexList$, $k$}\\
		}
	}
 	\caption{Cluster por distancia en KD-tree}
 	\label{alg:Cluster_por_distancia_en_KD_tree}
\end{algorithm}

Gracias a la estructura KD-tree, se puede reducir la cantidad de nodos o puntos analizados, ya que cada punto no tiene que ser estudiado con el resto sino que solo se estudian los puntos que están en una región cercana dentro del radio máximo de distancia definido. Lo que produce una complejidad de $O(n * \log n)$ para la construcción de la estructura más la complejidad $O(n * \log n)$ de la función de clustering por distancia, por lo que en total se tendría una mejora de complejidad de $O(n²)$ a $O(n * \log n)$.\par
La eficiencia de esta estructura en ciertas tareas, ha producido que a pesar de ser una técnica del año 1975, se siga estudiando para su utilización junto a \acs{knn} \cite{knn_kd_tree}, aumentando su rendimiento con datos preordenados \cite{kd_tree_presorted} o la paralelización de su construcción en técnicas como \acs{knn} \cite{kd_tree_gpu}.

\newpage

\section{Filtrado previo y posterior a la detección}
\label{sec:filtrado_previo_y_posterior_a_la_deteccion}

Tras la obtención de las detecciones por parte de los diversos algoritmos clásicos podemos encontrarnos ante diferentes problemas con dichas detecciones.\par
Estas pueden generar clústeres con pocos o demasiados puntos, lo que puede resultar en clústeres incorrectos. Aquellos con pocos puntos pueden identificar objetos lejanos u objetos que no son necesarios para el entendimiento de la escena, por otra parte, aquellas detecciones con muchos puntos pueden identificar camiones, vehículos de construcción o simplemente objetos muy cercanos, pero también es muy normal que las construcciones sean detectadas por lo que hay que filtrar tanto por un número máximo como mínimo de puntos para obtener mejores detecciones.\par
Otra práctica para el filtrado, es el ajuste a unos tamaños prefijados en todas las dimensiones, lo cual elimina aquellos objetos que no son similares a los vehículos que se desean detectar.\par
Estas técnicas de filtrado no solo se pueden utilizar tras la obtención de las detecciones, sino que la nube de puntos obtenida del \acs{lidar} es posible filtrarla, para que así solo se trabaje con una \ac{roi}, ya que a partir de cierta distancia las detecciones no van a ser muy precisas, para ello se puede filtrar también por distancia al vehículo. Además, un filtrado que permita trabajar unicamente con la parte delantera y trasera del coche, aporta una reducción en el computo de los algoritmos, a la vez que se reducen las falsas detecciones.
